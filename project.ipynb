{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import ast \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\polam\\OneDrive\\Desktop\\New folder\\master.csv\", header=None, names=['Car', 'Values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Values'] = df['Values'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_split = pd.DataFrame(df['Values'].tolist(), columns=[f'Column {i+1}' for i in range(len(df['Values'][0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column 1</th>\n",
       "      <th>Column 2</th>\n",
       "      <th>Column 3</th>\n",
       "      <th>Column 4</th>\n",
       "      <th>Column 5</th>\n",
       "      <th>Column 6</th>\n",
       "      <th>Column 7</th>\n",
       "      <th>Column 8</th>\n",
       "      <th>Column 9</th>\n",
       "      <th>Column 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Column 5891</th>\n",
       "      <th>Column 5892</th>\n",
       "      <th>Column 5893</th>\n",
       "      <th>Column 5894</th>\n",
       "      <th>Column 5895</th>\n",
       "      <th>Column 5896</th>\n",
       "      <th>Column 5897</th>\n",
       "      <th>Column 5898</th>\n",
       "      <th>Column 5899</th>\n",
       "      <th>Column 5900</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4286</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4287</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4288</th>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4289</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4290</th>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4291 rows × 5900 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Column 1  Column 2  Column 3  Column 4  Column 5  Column 6  Column 7  \\\n",
       "0     0.000049  0.000049  0.001000  0.000049  0.000049  0.000049  0.000049   \n",
       "1     0.000038  0.000039  0.000039  0.000038  0.000038  0.000038  0.000038   \n",
       "2     0.000040  0.000040  0.000040  0.000040  0.000040  0.000040  0.000040   \n",
       "3     0.000041  0.000041  0.000041  0.000041  0.000041  0.000041  0.000041   \n",
       "4     0.000046  0.000045  0.001000  0.000046  0.000045  0.000045  0.000045   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4286  0.001000  0.001000  0.001000  0.001000  0.001000  0.001000  0.001000   \n",
       "4287  0.001000  0.000052  0.001000  0.001000  0.000052  0.001000  0.001000   \n",
       "4288  0.000052  0.000052  0.000052  0.001000  0.000052  0.000052  0.000052   \n",
       "4289  0.001000  0.001000  0.001000  0.001000  0.001000  0.001000  0.001000   \n",
       "4290  0.000051  0.000052  0.000052  0.000052  0.000051  0.000051  0.000051   \n",
       "\n",
       "      Column 8  Column 9  Column 10  ...  Column 5891  Column 5892  \\\n",
       "0     0.000049  0.000049   0.000049  ...        0.001        0.001   \n",
       "1     0.000038  0.000038   0.000038  ...        0.001        0.001   \n",
       "2     0.000040  0.000040   0.000040  ...        0.001        0.001   \n",
       "3     0.000041  0.000041   0.000041  ...        0.001        0.001   \n",
       "4     0.000045  0.000045   0.000045  ...        0.001        0.001   \n",
       "...        ...       ...        ...  ...          ...          ...   \n",
       "4286  0.001000  0.001000   0.001000  ...        0.001        0.001   \n",
       "4287  0.001000  0.000052   0.001000  ...        0.001        0.001   \n",
       "4288  0.000052  0.000052   0.000052  ...        0.001        0.001   \n",
       "4289  0.001000  0.001000   0.001000  ...        0.001        0.001   \n",
       "4290  0.000052  0.000051   0.000049  ...        0.001        0.001   \n",
       "\n",
       "      Column 5893  Column 5894  Column 5895  Column 5896  Column 5897  \\\n",
       "0           0.001        0.001        0.001        0.001        0.001   \n",
       "1           0.001        0.001        0.001        0.001        0.001   \n",
       "2           0.001        0.001        0.001        0.001        0.001   \n",
       "3           0.001        0.001        0.001        0.001        0.001   \n",
       "4           0.001        0.001        0.001        0.001        0.001   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "4286        0.001        0.001        0.001        0.001        0.001   \n",
       "4287        0.001        0.001        0.001        0.001        0.001   \n",
       "4288        0.001        0.001        0.001        0.001        0.001   \n",
       "4289        0.001        0.001        0.001        0.001        0.001   \n",
       "4290        0.001        0.001        0.001        0.001        0.001   \n",
       "\n",
       "      Column 5898  Column 5899  Column 5900  \n",
       "0           0.001        0.001        0.001  \n",
       "1           0.001        0.001        0.001  \n",
       "2           0.001        0.001        0.001  \n",
       "3           0.001        0.001        0.001  \n",
       "4           0.001        0.001        0.001  \n",
       "...           ...          ...          ...  \n",
       "4286        0.001        0.001        0.001  \n",
       "4287        0.001        0.001        0.001  \n",
       "4288        0.001        0.001        0.001  \n",
       "4289        0.001        0.001        0.001  \n",
       "4290        0.001        0.001        0.001  \n",
       "\n",
       "[4291 rows x 5900 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([df['Car'], values_split], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4291, 5901)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car</th>\n",
       "      <th>Column 1</th>\n",
       "      <th>Column 2</th>\n",
       "      <th>Column 3</th>\n",
       "      <th>Column 4</th>\n",
       "      <th>Column 5</th>\n",
       "      <th>Column 6</th>\n",
       "      <th>Column 7</th>\n",
       "      <th>Column 8</th>\n",
       "      <th>Column 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Column 5891</th>\n",
       "      <th>Column 5892</th>\n",
       "      <th>Column 5893</th>\n",
       "      <th>Column 5894</th>\n",
       "      <th>Column 5895</th>\n",
       "      <th>Column 5896</th>\n",
       "      <th>Column 5897</th>\n",
       "      <th>Column 5898</th>\n",
       "      <th>Column 5899</th>\n",
       "      <th>Column 5900</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Car</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Car</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Car</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Car</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Car</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5901 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Car  Column 1  Column 2  Column 3  Column 4  Column 5  Column 6  Column 7  \\\n",
       "0  Car  0.000049  0.000049  0.001000  0.000049  0.000049  0.000049  0.000049   \n",
       "1  Car  0.000038  0.000039  0.000039  0.000038  0.000038  0.000038  0.000038   \n",
       "2  Car  0.000040  0.000040  0.000040  0.000040  0.000040  0.000040  0.000040   \n",
       "3  Car  0.000041  0.000041  0.000041  0.000041  0.000041  0.000041  0.000041   \n",
       "4  Car  0.000046  0.000045  0.001000  0.000046  0.000045  0.000045  0.000045   \n",
       "\n",
       "   Column 8  Column 9  ...  Column 5891  Column 5892  Column 5893  \\\n",
       "0  0.000049  0.000049  ...        0.001        0.001        0.001   \n",
       "1  0.000038  0.000038  ...        0.001        0.001        0.001   \n",
       "2  0.000040  0.000040  ...        0.001        0.001        0.001   \n",
       "3  0.000041  0.000041  ...        0.001        0.001        0.001   \n",
       "4  0.000045  0.000045  ...        0.001        0.001        0.001   \n",
       "\n",
       "   Column 5894  Column 5895  Column 5896  Column 5897  Column 5898  \\\n",
       "0        0.001        0.001        0.001        0.001        0.001   \n",
       "1        0.001        0.001        0.001        0.001        0.001   \n",
       "2        0.001        0.001        0.001        0.001        0.001   \n",
       "3        0.001        0.001        0.001        0.001        0.001   \n",
       "4        0.001        0.001        0.001        0.001        0.001   \n",
       "\n",
       "   Column 5899  Column 5900  \n",
       "0        0.001        0.001  \n",
       "1        0.001        0.001  \n",
       "2        0.001        0.001  \n",
       "3        0.001        0.001  \n",
       "4        0.001        0.001  \n",
       "\n",
       "[5 rows x 5901 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car</th>\n",
       "      <th>Column 1</th>\n",
       "      <th>Column 2</th>\n",
       "      <th>Column 3</th>\n",
       "      <th>Column 4</th>\n",
       "      <th>Column 5</th>\n",
       "      <th>Column 6</th>\n",
       "      <th>Column 7</th>\n",
       "      <th>Column 8</th>\n",
       "      <th>Column 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Column 5891</th>\n",
       "      <th>Column 5892</th>\n",
       "      <th>Column 5893</th>\n",
       "      <th>Column 5894</th>\n",
       "      <th>Column 5895</th>\n",
       "      <th>Column 5896</th>\n",
       "      <th>Column 5897</th>\n",
       "      <th>Column 5898</th>\n",
       "      <th>Column 5899</th>\n",
       "      <th>Column 5900</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4286</th>\n",
       "      <td>Car</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4287</th>\n",
       "      <td>Car</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4288</th>\n",
       "      <td>Car</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4289</th>\n",
       "      <td>Van</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4290</th>\n",
       "      <td>Car</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5901 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Car  Column 1  Column 2  Column 3  Column 4  Column 5  Column 6  \\\n",
       "4286  Car  0.001000  0.001000  0.001000  0.001000  0.001000  0.001000   \n",
       "4287  Car  0.001000  0.000052  0.001000  0.001000  0.000052  0.001000   \n",
       "4288  Car  0.000052  0.000052  0.000052  0.001000  0.000052  0.000052   \n",
       "4289  Van  0.001000  0.001000  0.001000  0.001000  0.001000  0.001000   \n",
       "4290  Car  0.000051  0.000052  0.000052  0.000052  0.000051  0.000051   \n",
       "\n",
       "      Column 7  Column 8  Column 9  ...  Column 5891  Column 5892  \\\n",
       "4286  0.001000  0.001000  0.001000  ...        0.001        0.001   \n",
       "4287  0.001000  0.001000  0.000052  ...        0.001        0.001   \n",
       "4288  0.000052  0.000052  0.000052  ...        0.001        0.001   \n",
       "4289  0.001000  0.001000  0.001000  ...        0.001        0.001   \n",
       "4290  0.000051  0.000052  0.000051  ...        0.001        0.001   \n",
       "\n",
       "      Column 5893  Column 5894  Column 5895  Column 5896  Column 5897  \\\n",
       "4286        0.001        0.001        0.001        0.001        0.001   \n",
       "4287        0.001        0.001        0.001        0.001        0.001   \n",
       "4288        0.001        0.001        0.001        0.001        0.001   \n",
       "4289        0.001        0.001        0.001        0.001        0.001   \n",
       "4290        0.001        0.001        0.001        0.001        0.001   \n",
       "\n",
       "      Column 5898  Column 5899  Column 5900  \n",
       "4286        0.001        0.001        0.001  \n",
       "4287        0.001        0.001        0.001  \n",
       "4288        0.001        0.001        0.001  \n",
       "4289        0.001        0.001        0.001  \n",
       "4290        0.001        0.001        0.001  \n",
       "\n",
       "[5 rows x 5901 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    5901\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null = (df.isnull().sum()>=1).value_counts()\n",
    "null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4291 entries, 0 to 4290\n",
      "Columns: 5901 entries, Car to Column 5900\n",
      "dtypes: float64(5900), object(1)\n",
      "memory usage: 193.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"cleaned_data.csv\", index=False) # Save the cleaned data to a new csv file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(\"Car\", axis=1)\n",
    "y = df[\"Car\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Car\n",
       "Car               3015\n",
       "Pedestrian         508\n",
       "Van                313\n",
       "Cyclist            171\n",
       "Truck              110\n",
       "Misc               106\n",
       "Tram                51\n",
       "Person_sitting      17\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car</th>\n",
       "      <th>Cyclist</th>\n",
       "      <th>Misc</th>\n",
       "      <th>Pedestrian</th>\n",
       "      <th>Person_sitting</th>\n",
       "      <th>Tram</th>\n",
       "      <th>Truck</th>\n",
       "      <th>Van</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4286</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4287</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4288</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4289</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4290</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4291 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Car  Cyclist   Misc  Pedestrian  Person_sitting   Tram  Truck    Van\n",
       "0      True    False  False       False           False  False  False  False\n",
       "1      True    False  False       False           False  False  False  False\n",
       "2      True    False  False       False           False  False  False  False\n",
       "3      True    False  False       False           False  False  False  False\n",
       "4      True    False  False       False           False  False  False  False\n",
       "...     ...      ...    ...         ...             ...    ...    ...    ...\n",
       "4286   True    False  False       False           False  False  False  False\n",
       "4287   True    False  False       False           False  False  False  False\n",
       "4288   True    False  False       False           False  False  False  False\n",
       "4289  False    False  False       False           False  False  False   True\n",
       "4290   True    False  False       False           False  False  False  False\n",
       "\n",
       "[4291 rows x 8 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3861, 5900), (430, 5900), (3861, 8), (430, 8))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "x_train = scalar.fit_transform(x_train)\n",
    "x_test = scalar.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(5900,)),#h1\n",
    "    Dense(128, activation='relu'),#h2                \n",
    "    Dense(8, activation='softmax')  # Output layer                  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,510,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m1,510,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m1,032\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,544,584</span> (5.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,544,584\u001b[0m (5.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,544,584</span> (5.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,544,584\u001b[0m (5.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for 10 epochs:\n",
      "Epoch 1/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5958 - loss: 1.8262 - val_accuracy: 0.6721 - val_loss: 1.2258\n",
      "Epoch 2/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7740 - loss: 0.7573 - val_accuracy: 0.6581 - val_loss: 1.3069\n",
      "Epoch 3/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8598 - loss: 0.4506 - val_accuracy: 0.6744 - val_loss: 1.2857\n",
      "Epoch 4/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9311 - loss: 0.2152 - val_accuracy: 0.6814 - val_loss: 1.3126\n",
      "Epoch 5/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9755 - loss: 0.0986 - val_accuracy: 0.6930 - val_loss: 1.4655\n",
      "Epoch 6/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9820 - loss: 0.0663 - val_accuracy: 0.7047 - val_loss: 1.5058\n",
      "Epoch 7/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9881 - loss: 0.0513 - val_accuracy: 0.7116 - val_loss: 1.5548\n",
      "Epoch 8/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9903 - loss: 0.0311 - val_accuracy: 0.7093 - val_loss: 1.5218\n",
      "Epoch 9/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9860 - loss: 0.0598 - val_accuracy: 0.6721 - val_loss: 1.6449\n",
      "Epoch 10/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9837 - loss: 0.0668 - val_accuracy: 0.6930 - val_loss: 2.1011\n",
      "\n",
      "Training for 20 epochs:\n",
      "Epoch 1/20\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9501 - loss: 0.1865 - val_accuracy: 0.6744 - val_loss: 2.2671\n",
      "Epoch 2/20\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9391 - loss: 0.2145 - val_accuracy: 0.6605 - val_loss: 2.1793\n",
      "Epoch 3/20\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9617 - loss: 0.1218 - val_accuracy: 0.6372 - val_loss: 2.1243\n",
      "Epoch 4/20\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9834 - loss: 0.0473 - val_accuracy: 0.6860 - val_loss: 2.0856\n",
      "Epoch 5/20\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9909 - loss: 0.0311 - val_accuracy: 0.7070 - val_loss: 2.2641\n",
      "Epoch 6/20\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9946 - loss: 0.0199 - val_accuracy: 0.7070 - val_loss: 2.1257\n",
      "Epoch 7/20\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9965 - loss: 0.0140 - val_accuracy: 0.7209 - val_loss: 2.2345\n",
      "Epoch 8/20\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9944 - loss: 0.0169 - val_accuracy: 0.7233 - val_loss: 2.2431\n",
      "Epoch 9/20\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0046 - val_accuracy: 0.7093 - val_loss: 2.3483\n",
      "Epoch 10/20\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.7233 - val_loss: 2.1529\n",
      "Epoch 11/20\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 5.1410e-04 - val_accuracy: 0.7233 - val_loss: 2.1923\n",
      "Epoch 12/20\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 5.1681e-04 - val_accuracy: 0.7163 - val_loss: 2.2287\n",
      "Epoch 13/20\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.1880e-04 - val_accuracy: 0.7209 - val_loss: 2.2501\n",
      "Epoch 14/20\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 9.7833e-04 - val_accuracy: 0.7209 - val_loss: 2.2529\n",
      "Epoch 15/20\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 5.8116e-04 - val_accuracy: 0.7233 - val_loss: 2.2549\n",
      "Epoch 16/20\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 3.5642e-04 - val_accuracy: 0.7256 - val_loss: 2.2801\n",
      "Epoch 17/20\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 2.2320e-04 - val_accuracy: 0.7233 - val_loss: 2.2838\n",
      "Epoch 18/20\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 3.2534e-04 - val_accuracy: 0.7233 - val_loss: 2.2935\n",
      "Epoch 19/20\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.7233 - val_loss: 2.3083\n",
      "Epoch 20/20\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 7.1665e-04 - val_accuracy: 0.7256 - val_loss: 2.2984\n",
      "\n",
      "Training for 40 epochs:\n",
      "Epoch 1/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 6.3833e-04 - val_accuracy: 0.7256 - val_loss: 2.2961\n",
      "Epoch 2/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 3.2026e-04 - val_accuracy: 0.7256 - val_loss: 2.3183\n",
      "Epoch 3/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.7575e-05 - val_accuracy: 0.7279 - val_loss: 2.3187\n",
      "Epoch 4/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9990 - loss: 8.5236e-04 - val_accuracy: 0.7233 - val_loss: 2.3222\n",
      "Epoch 5/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 2.2626e-04 - val_accuracy: 0.7256 - val_loss: 2.3174\n",
      "Epoch 6/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 4.3907e-04 - val_accuracy: 0.7256 - val_loss: 2.3252\n",
      "Epoch 7/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.6124e-04 - val_accuracy: 0.7256 - val_loss: 2.3446\n",
      "Epoch 8/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 2.4583e-04 - val_accuracy: 0.7302 - val_loss: 2.4051\n",
      "Epoch 9/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 4.9857e-04 - val_accuracy: 0.7233 - val_loss: 2.2962\n",
      "Epoch 10/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9992 - loss: 9.6862e-04 - val_accuracy: 0.7233 - val_loss: 2.3473\n",
      "Epoch 11/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.1607e-04 - val_accuracy: 0.7233 - val_loss: 2.5052\n",
      "Epoch 12/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 5.0257e-04 - val_accuracy: 0.7163 - val_loss: 2.3388\n",
      "Epoch 13/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9874 - loss: 0.0906 - val_accuracy: 0.5907 - val_loss: 2.3440\n",
      "Epoch 14/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7161 - loss: 1.1175 - val_accuracy: 0.6442 - val_loss: 1.2767\n",
      "Epoch 15/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7540 - loss: 0.7043 - val_accuracy: 0.6767 - val_loss: 1.3255\n",
      "Epoch 16/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8092 - loss: 0.4741 - val_accuracy: 0.6488 - val_loss: 1.4418\n",
      "Epoch 17/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8593 - loss: 0.3431 - val_accuracy: 0.6581 - val_loss: 1.7152\n",
      "Epoch 18/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9145 - loss: 0.2204 - val_accuracy: 0.6581 - val_loss: 2.0084\n",
      "Epoch 19/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9261 - loss: 0.1726 - val_accuracy: 0.6860 - val_loss: 1.8920\n",
      "Epoch 20/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9547 - loss: 0.1248 - val_accuracy: 0.6837 - val_loss: 2.2837\n",
      "Epoch 21/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9701 - loss: 0.0916 - val_accuracy: 0.6744 - val_loss: 2.4211\n",
      "Epoch 22/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9617 - loss: 0.1102 - val_accuracy: 0.6395 - val_loss: 2.3936\n",
      "Epoch 23/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9606 - loss: 0.1307 - val_accuracy: 0.7047 - val_loss: 2.2664\n",
      "Epoch 24/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9755 - loss: 0.0716 - val_accuracy: 0.6721 - val_loss: 2.5500\n",
      "Epoch 25/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9726 - loss: 0.1082 - val_accuracy: 0.7047 - val_loss: 2.3057\n",
      "Epoch 26/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9763 - loss: 0.0687 - val_accuracy: 0.7140 - val_loss: 2.3433\n",
      "Epoch 27/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9903 - loss: 0.0314 - val_accuracy: 0.7023 - val_loss: 2.3662\n",
      "Epoch 28/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9914 - loss: 0.0275 - val_accuracy: 0.6953 - val_loss: 2.4384\n",
      "Epoch 29/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9882 - loss: 0.0279 - val_accuracy: 0.6930 - val_loss: 2.5259\n",
      "Epoch 30/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9892 - loss: 0.0369 - val_accuracy: 0.6977 - val_loss: 2.5218\n",
      "Epoch 31/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9943 - loss: 0.0138 - val_accuracy: 0.7047 - val_loss: 2.5554\n",
      "Epoch 32/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9951 - loss: 0.0125 - val_accuracy: 0.7047 - val_loss: 2.6011\n",
      "Epoch 33/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9982 - loss: 0.0053 - val_accuracy: 0.7070 - val_loss: 2.5885\n",
      "Epoch 34/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9950 - loss: 0.0168 - val_accuracy: 0.6884 - val_loss: 2.5502\n",
      "Epoch 35/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9710 - loss: 0.1137 - val_accuracy: 0.6907 - val_loss: 3.1120\n",
      "Epoch 36/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9347 - loss: 0.2539 - val_accuracy: 0.7000 - val_loss: 2.4740\n",
      "Epoch 37/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9792 - loss: 0.0606 - val_accuracy: 0.6837 - val_loss: 3.0511\n",
      "Epoch 38/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9866 - loss: 0.0465 - val_accuracy: 0.6837 - val_loss: 2.8137\n",
      "Epoch 39/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9937 - loss: 0.0191 - val_accuracy: 0.6930 - val_loss: 2.8410\n",
      "Epoch 40/40\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9951 - loss: 0.0150 - val_accuracy: 0.6651 - val_loss: 2.8689\n",
      "\n",
      "Training for 60 epochs:\n",
      "Epoch 1/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9953 - loss: 0.0142 - val_accuracy: 0.6860 - val_loss: 2.8347\n",
      "Epoch 2/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9970 - loss: 0.0115 - val_accuracy: 0.7070 - val_loss: 2.9093\n",
      "Epoch 3/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0026 - val_accuracy: 0.7186 - val_loss: 2.9807\n",
      "Epoch 4/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 9.2993e-04 - val_accuracy: 0.7023 - val_loss: 2.9645\n",
      "Epoch 5/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.7070 - val_loss: 3.0074\n",
      "Epoch 6/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 0.7047 - val_loss: 3.0119\n",
      "Epoch 7/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 9.4651e-04 - val_accuracy: 0.7070 - val_loss: 3.0407\n",
      "Epoch 8/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 0.7070 - val_loss: 3.0667\n",
      "Epoch 9/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.7140 - val_loss: 3.0982\n",
      "Epoch 10/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9766 - loss: 0.1024 - val_accuracy: 0.6651 - val_loss: 3.8492\n",
      "Epoch 11/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9311 - loss: 0.2501 - val_accuracy: 0.6977 - val_loss: 2.6309\n",
      "Epoch 12/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9692 - loss: 0.0930 - val_accuracy: 0.6651 - val_loss: 2.6893\n",
      "Epoch 13/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9885 - loss: 0.0386 - val_accuracy: 0.6674 - val_loss: 2.9647\n",
      "Epoch 14/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9942 - loss: 0.0214 - val_accuracy: 0.6884 - val_loss: 2.9581\n",
      "Epoch 15/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9987 - loss: 0.0060 - val_accuracy: 0.7047 - val_loss: 3.0816\n",
      "Epoch 16/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0043 - val_accuracy: 0.6884 - val_loss: 3.0457\n",
      "Epoch 17/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 9.1700e-04 - val_accuracy: 0.6907 - val_loss: 3.0910\n",
      "Epoch 18/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 6.9724e-04 - val_accuracy: 0.6884 - val_loss: 3.1018\n",
      "Epoch 19/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 6.7611e-04 - val_accuracy: 0.6907 - val_loss: 3.1151\n",
      "Epoch 20/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 8.1513e-04 - val_accuracy: 0.6930 - val_loss: 3.1260\n",
      "Epoch 21/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 9.6918e-04 - val_accuracy: 0.6930 - val_loss: 3.1390\n",
      "Epoch 22/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 7.1070e-04 - val_accuracy: 0.6930 - val_loss: 3.1577\n",
      "Epoch 23/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.8964e-04 - val_accuracy: 0.6930 - val_loss: 3.1734\n",
      "Epoch 24/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.6907 - val_loss: 3.1972\n",
      "Epoch 25/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 7.8314e-04 - val_accuracy: 0.6977 - val_loss: 3.1754\n",
      "Epoch 26/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 7.8771e-04 - val_accuracy: 0.7000 - val_loss: 3.1987\n",
      "Epoch 27/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 4.1228e-04 - val_accuracy: 0.6977 - val_loss: 3.2399\n",
      "Epoch 28/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 8.5630e-04 - val_accuracy: 0.7000 - val_loss: 3.1964\n",
      "Epoch 29/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 0.0014 - val_accuracy: 0.7000 - val_loss: 3.1898\n",
      "Epoch 30/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 7.5934e-04 - val_accuracy: 0.6953 - val_loss: 3.2692\n",
      "Epoch 31/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.5471e-04 - val_accuracy: 0.6953 - val_loss: 3.2755\n",
      "Epoch 32/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.6953 - val_loss: 3.2732\n",
      "Epoch 33/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 5.8997e-04 - val_accuracy: 0.6953 - val_loss: 3.2722\n",
      "Epoch 34/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 9.6455e-04 - val_accuracy: 0.6953 - val_loss: 3.2923\n",
      "Epoch 35/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 9.0843e-04 - val_accuracy: 0.6953 - val_loss: 3.3194\n",
      "Epoch 36/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.6977 - val_loss: 3.3159\n",
      "Epoch 37/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.4470e-04 - val_accuracy: 0.7070 - val_loss: 3.2449\n",
      "Epoch 38/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 9.5448e-04 - val_accuracy: 0.7047 - val_loss: 3.3939\n",
      "Epoch 39/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 7.4589e-04 - val_accuracy: 0.7093 - val_loss: 3.3200\n",
      "Epoch 40/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0020 - val_accuracy: 0.7047 - val_loss: 3.3006\n",
      "Epoch 41/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 8.0330e-04 - val_accuracy: 0.7093 - val_loss: 3.3229\n",
      "Epoch 42/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.7093 - val_loss: 3.3475\n",
      "Epoch 43/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.6591e-04 - val_accuracy: 0.7093 - val_loss: 3.3787\n",
      "Epoch 44/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.7116 - val_loss: 3.3863\n",
      "Epoch 45/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.8554e-04 - val_accuracy: 0.7116 - val_loss: 3.3930\n",
      "Epoch 46/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.7116 - val_loss: 3.4133\n",
      "Epoch 47/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0016 - val_accuracy: 0.7116 - val_loss: 3.4167\n",
      "Epoch 48/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 5.6188e-04 - val_accuracy: 0.7116 - val_loss: 3.4239\n",
      "Epoch 49/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.7116 - val_loss: 3.4391\n",
      "Epoch 50/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 4.4880e-04 - val_accuracy: 0.7116 - val_loss: 3.4469\n",
      "Epoch 51/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 4.2601e-04 - val_accuracy: 0.7116 - val_loss: 3.4685\n",
      "Epoch 52/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 7.5329e-04 - val_accuracy: 0.7116 - val_loss: 3.4681\n",
      "Epoch 53/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.8164e-04 - val_accuracy: 0.7116 - val_loss: 3.4867\n",
      "Epoch 54/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 9.4917e-04 - val_accuracy: 0.7140 - val_loss: 3.4957\n",
      "Epoch 55/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 4.0535e-04 - val_accuracy: 0.7116 - val_loss: 3.5253\n",
      "Epoch 56/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.5457e-04 - val_accuracy: 0.7070 - val_loss: 3.6070\n",
      "Epoch 57/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9840 - loss: 0.1153 - val_accuracy: 0.5465 - val_loss: 4.0746\n",
      "Epoch 58/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8332 - loss: 0.5984 - val_accuracy: 0.6791 - val_loss: 2.4898\n",
      "Epoch 59/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9401 - loss: 0.1635 - val_accuracy: 0.6674 - val_loss: 2.4793\n",
      "Epoch 60/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9688 - loss: 0.0894 - val_accuracy: 0.6884 - val_loss: 3.1664\n",
      "\n",
      "Training for 70 epochs:\n",
      "Epoch 1/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9831 - loss: 0.0517 - val_accuracy: 0.6884 - val_loss: 3.0102\n",
      "Epoch 2/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9837 - loss: 0.0525 - val_accuracy: 0.6884 - val_loss: 3.1225\n",
      "Epoch 3/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9890 - loss: 0.0418 - val_accuracy: 0.6860 - val_loss: 3.0315\n",
      "Epoch 4/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9864 - loss: 0.0405 - val_accuracy: 0.6884 - val_loss: 4.0634\n",
      "Epoch 5/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9852 - loss: 0.0393 - val_accuracy: 0.7047 - val_loss: 3.6463\n",
      "Epoch 6/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9900 - loss: 0.0280 - val_accuracy: 0.6930 - val_loss: 3.5969\n",
      "Epoch 7/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9973 - loss: 0.0097 - val_accuracy: 0.6953 - val_loss: 3.5081\n",
      "Epoch 8/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9879 - loss: 0.0429 - val_accuracy: 0.6884 - val_loss: 3.6226\n",
      "Epoch 9/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9927 - loss: 0.0266 - val_accuracy: 0.6977 - val_loss: 4.1858\n",
      "Epoch 10/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9882 - loss: 0.0331 - val_accuracy: 0.6791 - val_loss: 3.9595\n",
      "Epoch 11/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9936 - loss: 0.0335 - val_accuracy: 0.7140 - val_loss: 4.3339\n",
      "Epoch 12/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9947 - loss: 0.0278 - val_accuracy: 0.7116 - val_loss: 3.9858\n",
      "Epoch 13/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9992 - loss: 0.0042 - val_accuracy: 0.7000 - val_loss: 4.1622\n",
      "Epoch 14/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.0077 - val_accuracy: 0.7116 - val_loss: 4.1129\n",
      "Epoch 15/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9987 - loss: 0.0047 - val_accuracy: 0.7093 - val_loss: 3.9548\n",
      "Epoch 16/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.8834e-04 - val_accuracy: 0.7093 - val_loss: 3.9672\n",
      "Epoch 17/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 5.1810e-04 - val_accuracy: 0.7116 - val_loss: 4.0075\n",
      "Epoch 18/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 4.0967e-04 - val_accuracy: 0.7116 - val_loss: 4.0331\n",
      "Epoch 19/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 5.6738e-04 - val_accuracy: 0.7140 - val_loss: 4.0538\n",
      "Epoch 20/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 0.0017 - val_accuracy: 0.6860 - val_loss: 4.5337\n",
      "Epoch 21/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9841 - loss: 0.0793 - val_accuracy: 0.6558 - val_loss: 4.0768\n",
      "Epoch 22/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9862 - loss: 0.0541 - val_accuracy: 0.6465 - val_loss: 4.2875\n",
      "Epoch 23/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9857 - loss: 0.0600 - val_accuracy: 0.6721 - val_loss: 4.7165\n",
      "Epoch 24/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9978 - loss: 0.0102 - val_accuracy: 0.6395 - val_loss: 4.7394\n",
      "Epoch 25/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9923 - loss: 0.0350 - val_accuracy: 0.7000 - val_loss: 4.2884\n",
      "Epoch 26/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9964 - loss: 0.0123 - val_accuracy: 0.6884 - val_loss: 4.3288\n",
      "Epoch 27/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9978 - loss: 0.0062 - val_accuracy: 0.6907 - val_loss: 4.4552\n",
      "Epoch 28/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 7.2084e-04 - val_accuracy: 0.6860 - val_loss: 4.5148\n",
      "Epoch 29/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.6930 - val_loss: 4.4907\n",
      "Epoch 30/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9992 - loss: 8.7735e-04 - val_accuracy: 0.6884 - val_loss: 4.5078\n",
      "Epoch 31/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 1.4550e-04 - val_accuracy: 0.6907 - val_loss: 4.5154\n",
      "Epoch 32/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 3.3691e-04 - val_accuracy: 0.6930 - val_loss: 4.5392\n",
      "Epoch 33/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 2.0381e-04 - val_accuracy: 0.6930 - val_loss: 4.5490\n",
      "Epoch 34/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 5.7058e-04 - val_accuracy: 0.6930 - val_loss: 4.5584\n",
      "Epoch 35/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.4887e-04 - val_accuracy: 0.6930 - val_loss: 4.5675\n",
      "Epoch 36/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 3.8466e-04 - val_accuracy: 0.6930 - val_loss: 4.5759\n",
      "Epoch 37/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3743e-04 - val_accuracy: 0.6953 - val_loss: 4.5818\n",
      "Epoch 38/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 8.9423e-04 - val_accuracy: 0.6977 - val_loss: 4.6226\n",
      "Epoch 39/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 2.8495e-04 - val_accuracy: 0.6930 - val_loss: 4.6156\n",
      "Epoch 40/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 3.2364e-04 - val_accuracy: 0.6953 - val_loss: 4.6282\n",
      "Epoch 41/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.3366e-04 - val_accuracy: 0.6930 - val_loss: 4.6519\n",
      "Epoch 42/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 7.2590e-05 - val_accuracy: 0.6907 - val_loss: 4.6463\n",
      "Epoch 43/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 2.9795e-04 - val_accuracy: 0.6930 - val_loss: 4.6607\n",
      "Epoch 44/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 1.9479e-04 - val_accuracy: 0.6930 - val_loss: 4.6666\n",
      "Epoch 45/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 3.8171e-04 - val_accuracy: 0.6930 - val_loss: 4.6767\n",
      "Epoch 46/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 7.0130e-04 - val_accuracy: 0.6930 - val_loss: 4.6728\n",
      "Epoch 47/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 4.0509e-04 - val_accuracy: 0.6930 - val_loss: 4.6880\n",
      "Epoch 48/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 9.7775e-05 - val_accuracy: 0.6930 - val_loss: 4.6964\n",
      "Epoch 49/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 3.8641e-04 - val_accuracy: 0.6930 - val_loss: 4.7025\n",
      "Epoch 50/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 0.0012 - val_accuracy: 0.6930 - val_loss: 4.7195\n",
      "Epoch 51/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 1.5473e-04 - val_accuracy: 0.6907 - val_loss: 4.7110\n",
      "Epoch 52/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0010 - val_accuracy: 0.6907 - val_loss: 4.7259\n",
      "Epoch 53/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 2.8513e-04 - val_accuracy: 0.6930 - val_loss: 4.7498\n",
      "Epoch 54/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 7.9086e-04 - val_accuracy: 0.6930 - val_loss: 4.7851\n",
      "Epoch 55/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 2.6190e-04 - val_accuracy: 0.6930 - val_loss: 4.6925\n",
      "Epoch 56/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9990 - loss: 0.0020 - val_accuracy: 0.6953 - val_loss: 4.7003\n",
      "Epoch 57/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 6.9744e-04 - val_accuracy: 0.6953 - val_loss: 4.7128\n",
      "Epoch 58/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 3.4003e-04 - val_accuracy: 0.6953 - val_loss: 4.7234\n",
      "Epoch 59/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 9.2971e-04 - val_accuracy: 0.6953 - val_loss: 4.7334\n",
      "Epoch 60/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0020 - val_accuracy: 0.6930 - val_loss: 4.7420\n",
      "Epoch 61/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9961 - loss: 0.0254 - val_accuracy: 0.6116 - val_loss: 4.2572\n",
      "Epoch 62/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8566 - loss: 0.5799 - val_accuracy: 0.6628 - val_loss: 2.7967\n",
      "Epoch 63/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9457 - loss: 0.1676 - val_accuracy: 0.6930 - val_loss: 2.9080\n",
      "Epoch 64/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9809 - loss: 0.0633 - val_accuracy: 0.7023 - val_loss: 3.3496\n",
      "Epoch 65/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9895 - loss: 0.0254 - val_accuracy: 0.6907 - val_loss: 2.9617\n",
      "Epoch 66/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9915 - loss: 0.0197 - val_accuracy: 0.6977 - val_loss: 3.5891\n",
      "Epoch 67/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9960 - loss: 0.0094 - val_accuracy: 0.6814 - val_loss: 3.6980\n",
      "Epoch 68/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9985 - loss: 0.0040 - val_accuracy: 0.6930 - val_loss: 3.7017\n",
      "Epoch 69/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0059 - val_accuracy: 0.6977 - val_loss: 4.2120\n",
      "Epoch 70/70\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9957 - loss: 0.0171 - val_accuracy: 0.7000 - val_loss: 4.3563\n",
      "\n",
      "Training for 100 epochs:\n",
      "Epoch 1/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.6977 - val_loss: 4.3088\n",
      "Epoch 2/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0022 - val_accuracy: 0.6930 - val_loss: 4.2467\n",
      "Epoch 3/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9992 - loss: 0.0038 - val_accuracy: 0.6930 - val_loss: 4.9382\n",
      "Epoch 4/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9902 - loss: 0.0477 - val_accuracy: 0.6930 - val_loss: 4.8336\n",
      "Epoch 5/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9873 - loss: 0.0316 - val_accuracy: 0.6767 - val_loss: 5.0755\n",
      "Epoch 6/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9911 - loss: 0.0397 - val_accuracy: 0.6953 - val_loss: 4.7832\n",
      "Epoch 7/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9858 - loss: 0.0658 - val_accuracy: 0.6837 - val_loss: 4.8601\n",
      "Epoch 8/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9829 - loss: 0.0751 - val_accuracy: 0.6814 - val_loss: 4.2623\n",
      "Epoch 9/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9955 - loss: 0.0124 - val_accuracy: 0.6953 - val_loss: 4.2185\n",
      "Epoch 10/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0027 - val_accuracy: 0.6953 - val_loss: 4.0040\n",
      "Epoch 11/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 4.9144e-04 - val_accuracy: 0.7000 - val_loss: 4.0914\n",
      "Epoch 12/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 6.0582e-04 - val_accuracy: 0.7000 - val_loss: 4.1322\n",
      "Epoch 13/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 5.5472e-04 - val_accuracy: 0.7047 - val_loss: 4.1725\n",
      "Epoch 14/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.4588e-04 - val_accuracy: 0.7047 - val_loss: 4.2025\n",
      "Epoch 15/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 2.1965e-04 - val_accuracy: 0.7047 - val_loss: 4.2242\n",
      "Epoch 16/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 1.4462e-04 - val_accuracy: 0.7023 - val_loss: 4.2567\n",
      "Epoch 17/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 5.7363e-04 - val_accuracy: 0.7023 - val_loss: 4.2897\n",
      "Epoch 18/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 1.3819e-04 - val_accuracy: 0.7023 - val_loss: 4.3041\n",
      "Epoch 19/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.3476e-04 - val_accuracy: 0.7023 - val_loss: 4.3254\n",
      "Epoch 20/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 6.4242e-04 - val_accuracy: 0.7047 - val_loss: 4.3472\n",
      "Epoch 21/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9986 - loss: 0.0011 - val_accuracy: 0.7047 - val_loss: 4.3603\n",
      "Epoch 22/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 6.6959e-04 - val_accuracy: 0.7047 - val_loss: 4.3781\n",
      "Epoch 23/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0010 - val_accuracy: 0.7070 - val_loss: 4.3934\n",
      "Epoch 24/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 2.9329e-04 - val_accuracy: 0.7047 - val_loss: 4.4137\n",
      "Epoch 25/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 3.7110e-04 - val_accuracy: 0.7070 - val_loss: 4.4333\n",
      "Epoch 26/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 1.4995e-04 - val_accuracy: 0.7070 - val_loss: 4.4464\n",
      "Epoch 27/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 9.0153e-04 - val_accuracy: 0.7070 - val_loss: 4.4614\n",
      "Epoch 28/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 1.2276e-04 - val_accuracy: 0.7070 - val_loss: 4.4796\n",
      "Epoch 29/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 3.2881e-04 - val_accuracy: 0.7070 - val_loss: 4.4989\n",
      "Epoch 30/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 8.8144e-04 - val_accuracy: 0.7093 - val_loss: 4.5095\n",
      "Epoch 31/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 3.5432e-04 - val_accuracy: 0.7093 - val_loss: 4.5276\n",
      "Epoch 32/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.2273e-04 - val_accuracy: 0.7093 - val_loss: 4.5478\n",
      "Epoch 33/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 4.8869e-04 - val_accuracy: 0.7093 - val_loss: 4.5702\n",
      "Epoch 34/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.2608e-04 - val_accuracy: 0.7093 - val_loss: 4.5834\n",
      "Epoch 35/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.8209e-04 - val_accuracy: 0.7093 - val_loss: 4.6006\n",
      "Epoch 36/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 5.2108e-04 - val_accuracy: 0.7070 - val_loss: 4.6079\n",
      "Epoch 37/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 9.9508e-04 - val_accuracy: 0.7070 - val_loss: 4.6218\n",
      "Epoch 38/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9988 - loss: 9.5506e-04 - val_accuracy: 0.7070 - val_loss: 4.6409\n",
      "Epoch 39/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 3.0011e-04 - val_accuracy: 0.7070 - val_loss: 4.6477\n",
      "Epoch 40/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 0.0010 - val_accuracy: 0.7070 - val_loss: 4.6628\n",
      "Epoch 41/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 5.8580e-04 - val_accuracy: 0.7070 - val_loss: 4.6744\n",
      "Epoch 42/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4808e-04 - val_accuracy: 0.7070 - val_loss: 4.7037\n",
      "Epoch 43/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 6.0197e-04 - val_accuracy: 0.7047 - val_loss: 4.6600\n",
      "Epoch 44/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9626 - loss: 0.2750 - val_accuracy: 0.6698 - val_loss: 3.4080\n",
      "Epoch 45/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9596 - loss: 0.1577 - val_accuracy: 0.6744 - val_loss: 3.8919\n",
      "Epoch 46/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9920 - loss: 0.0278 - val_accuracy: 0.6884 - val_loss: 4.3823\n",
      "Epoch 47/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9937 - loss: 0.0186 - val_accuracy: 0.6814 - val_loss: 4.0561\n",
      "Epoch 48/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.6814 - val_loss: 4.0727\n",
      "Epoch 49/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.6814 - val_loss: 4.1418\n",
      "Epoch 50/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.0708e-04 - val_accuracy: 0.6814 - val_loss: 4.1840\n",
      "Epoch 51/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9999 - loss: 5.3719e-04 - val_accuracy: 0.6814 - val_loss: 4.3062\n",
      "Epoch 52/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9999 - loss: 4.7350e-04 - val_accuracy: 0.6814 - val_loss: 4.3183\n",
      "Epoch 53/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9993 - loss: 9.2912e-04 - val_accuracy: 0.6837 - val_loss: 4.3317\n",
      "Epoch 54/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 5.0041e-04 - val_accuracy: 0.6860 - val_loss: 4.3858\n",
      "Epoch 55/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5218e-04 - val_accuracy: 0.6860 - val_loss: 4.3865\n",
      "Epoch 56/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9996 - loss: 0.0013 - val_accuracy: 0.6860 - val_loss: 4.3945\n",
      "Epoch 57/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 4.5609e-04 - val_accuracy: 0.6860 - val_loss: 4.4096\n",
      "Epoch 58/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 4.8825e-04 - val_accuracy: 0.6837 - val_loss: 4.4251\n",
      "Epoch 59/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9988 - loss: 0.0013 - val_accuracy: 0.6837 - val_loss: 4.4423\n",
      "Epoch 60/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9998 - loss: 4.0426e-04 - val_accuracy: 0.6860 - val_loss: 4.4575\n",
      "Epoch 61/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 5.8338e-04 - val_accuracy: 0.6860 - val_loss: 4.4776\n",
      "Epoch 62/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9993 - loss: 8.0451e-04 - val_accuracy: 0.6860 - val_loss: 4.4929\n",
      "Epoch 63/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9994 - loss: 6.6432e-04 - val_accuracy: 0.6884 - val_loss: 4.5085\n",
      "Epoch 64/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9986 - loss: 0.0014 - val_accuracy: 0.6884 - val_loss: 4.5228\n",
      "Epoch 65/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9994 - loss: 6.5063e-04 - val_accuracy: 0.6884 - val_loss: 4.5358\n",
      "Epoch 66/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 3.0762e-04 - val_accuracy: 0.6884 - val_loss: 4.5526\n",
      "Epoch 67/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 3.2381e-04 - val_accuracy: 0.6884 - val_loss: 4.5651\n",
      "Epoch 68/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9992 - loss: 7.3552e-04 - val_accuracy: 0.6884 - val_loss: 4.5771\n",
      "Epoch 69/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 1.9547e-04 - val_accuracy: 0.6884 - val_loss: 4.5963\n",
      "Epoch 70/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9994 - loss: 4.7041e-04 - val_accuracy: 0.6884 - val_loss: 4.6117\n",
      "Epoch 71/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 3.4097e-04 - val_accuracy: 0.6884 - val_loss: 4.6276\n",
      "Epoch 72/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1964e-04 - val_accuracy: 0.6884 - val_loss: 4.6420\n",
      "Epoch 73/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9993 - loss: 5.6776e-04 - val_accuracy: 0.6884 - val_loss: 4.6534\n",
      "Epoch 74/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9987 - loss: 9.9279e-04 - val_accuracy: 0.6884 - val_loss: 4.6673\n",
      "Epoch 75/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 3.4166e-04 - val_accuracy: 0.6884 - val_loss: 4.6889\n",
      "Epoch 76/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 6.6538e-04 - val_accuracy: 0.6884 - val_loss: 4.7016\n",
      "Epoch 77/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 3.5731e-04 - val_accuracy: 0.6884 - val_loss: 4.7204\n",
      "Epoch 78/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 5.8743e-05 - val_accuracy: 0.6907 - val_loss: 4.7337\n",
      "Epoch 79/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 8.0714e-04 - val_accuracy: 0.6907 - val_loss: 4.7514\n",
      "Epoch 80/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 6.4249e-04 - val_accuracy: 0.6907 - val_loss: 4.7733\n",
      "Epoch 81/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9992 - loss: 6.4904e-04 - val_accuracy: 0.6884 - val_loss: 4.7856\n",
      "Epoch 82/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 5.9422e-04 - val_accuracy: 0.6930 - val_loss: 4.8191\n",
      "Epoch 83/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 6.8863e-04 - val_accuracy: 0.6907 - val_loss: 4.8336\n",
      "Epoch 84/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 5.4530e-04 - val_accuracy: 0.6907 - val_loss: 4.8519\n",
      "Epoch 85/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 8.7596e-04 - val_accuracy: 0.6907 - val_loss: 4.8752\n",
      "Epoch 86/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 4.5674e-04 - val_accuracy: 0.6930 - val_loss: 4.8836\n",
      "Epoch 87/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9990 - loss: 8.0597e-04 - val_accuracy: 0.6930 - val_loss: 4.9076\n",
      "Epoch 88/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 3.9756e-04 - val_accuracy: 0.6977 - val_loss: 4.9273\n",
      "Epoch 89/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 6.6135e-04 - val_accuracy: 0.6977 - val_loss: 4.9498\n",
      "Epoch 90/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 4.4096e-04 - val_accuracy: 0.6930 - val_loss: 4.9821\n",
      "Epoch 91/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 7.7458e-04 - val_accuracy: 0.6907 - val_loss: 6.9753\n",
      "Epoch 92/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8889 - loss: 0.6216 - val_accuracy: 0.6233 - val_loss: 3.1922\n",
      "Epoch 93/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9357 - loss: 0.2468 - val_accuracy: 0.6349 - val_loss: 3.3549\n",
      "Epoch 94/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9801 - loss: 0.0638 - val_accuracy: 0.6791 - val_loss: 4.1935\n",
      "Epoch 95/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9870 - loss: 0.0359 - val_accuracy: 0.6791 - val_loss: 4.0290\n",
      "Epoch 96/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.0120 - val_accuracy: 0.6744 - val_loss: 4.3974\n",
      "Epoch 97/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9918 - loss: 0.0384 - val_accuracy: 0.6814 - val_loss: 4.2868\n",
      "Epoch 98/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9937 - loss: 0.0324 - val_accuracy: 0.6884 - val_loss: 4.5003\n",
      "Epoch 99/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9938 - loss: 0.0280 - val_accuracy: 0.6907 - val_loss: 4.5732\n",
      "Epoch 100/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9957 - loss: 0.0158 - val_accuracy: 0.6767 - val_loss: 4.7419\n"
     ]
    }
   ],
   "source": [
    "epochs_list = [10, 20, 40, 60, 70, 100]\n",
    "for epochs in epochs_list:\n",
    "    print(f\"\\nTraining for {epochs} epochs:\")\n",
    "    history = model.fit(x_train, y_train, epochs=epochs, batch_size=32, validation_data=(x_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-wise Training Accuracy:\n",
      "Epoch 1: Accuracy = 0.9992\n",
      "Epoch 2: Accuracy = 0.9992\n",
      "Epoch 3: Accuracy = 0.9979\n",
      "Epoch 4: Accuracy = 0.9876\n",
      "Epoch 5: Accuracy = 0.9912\n",
      "Epoch 6: Accuracy = 0.9915\n",
      "Epoch 7: Accuracy = 0.9863\n",
      "Epoch 8: Accuracy = 0.9821\n",
      "Epoch 9: Accuracy = 0.9959\n",
      "Epoch 10: Accuracy = 0.9992\n",
      "Epoch 11: Accuracy = 0.9997\n",
      "Epoch 12: Accuracy = 0.9997\n",
      "Epoch 13: Accuracy = 0.9995\n",
      "Epoch 14: Accuracy = 0.9997\n",
      "Epoch 15: Accuracy = 0.9995\n",
      "Epoch 16: Accuracy = 0.9995\n",
      "Epoch 17: Accuracy = 0.9995\n",
      "Epoch 18: Accuracy = 0.9995\n",
      "Epoch 19: Accuracy = 0.9997\n",
      "Epoch 20: Accuracy = 0.9995\n",
      "Epoch 21: Accuracy = 0.9995\n",
      "Epoch 22: Accuracy = 0.9997\n",
      "Epoch 23: Accuracy = 0.9997\n",
      "Epoch 24: Accuracy = 0.9995\n",
      "Epoch 25: Accuracy = 0.9995\n",
      "Epoch 26: Accuracy = 0.9997\n",
      "Epoch 27: Accuracy = 0.9995\n",
      "Epoch 28: Accuracy = 0.9995\n",
      "Epoch 29: Accuracy = 0.9997\n",
      "Epoch 30: Accuracy = 0.9995\n",
      "Epoch 31: Accuracy = 0.9997\n",
      "Epoch 32: Accuracy = 0.9997\n",
      "Epoch 33: Accuracy = 0.9997\n",
      "Epoch 34: Accuracy = 0.9997\n",
      "Epoch 35: Accuracy = 0.9997\n",
      "Epoch 36: Accuracy = 0.9995\n",
      "Epoch 37: Accuracy = 0.9997\n",
      "Epoch 38: Accuracy = 0.9995\n",
      "Epoch 39: Accuracy = 0.9995\n",
      "Epoch 40: Accuracy = 0.9997\n",
      "Epoch 41: Accuracy = 0.9997\n",
      "Epoch 42: Accuracy = 0.9997\n",
      "Epoch 43: Accuracy = 0.9997\n",
      "Epoch 44: Accuracy = 0.9311\n",
      "Epoch 45: Accuracy = 0.9692\n",
      "Epoch 46: Accuracy = 0.9927\n",
      "Epoch 47: Accuracy = 0.9959\n",
      "Epoch 48: Accuracy = 0.9997\n",
      "Epoch 49: Accuracy = 0.9997\n",
      "Epoch 50: Accuracy = 0.9997\n",
      "Epoch 51: Accuracy = 0.9997\n",
      "Epoch 52: Accuracy = 0.9997\n",
      "Epoch 53: Accuracy = 0.9995\n",
      "Epoch 54: Accuracy = 0.9997\n",
      "Epoch 55: Accuracy = 0.9997\n",
      "Epoch 56: Accuracy = 0.9997\n",
      "Epoch 57: Accuracy = 0.9997\n",
      "Epoch 58: Accuracy = 0.9995\n",
      "Epoch 59: Accuracy = 0.9995\n",
      "Epoch 60: Accuracy = 0.9997\n",
      "Epoch 61: Accuracy = 0.9997\n",
      "Epoch 62: Accuracy = 0.9995\n",
      "Epoch 63: Accuracy = 0.9995\n",
      "Epoch 64: Accuracy = 0.9995\n",
      "Epoch 65: Accuracy = 0.9995\n",
      "Epoch 66: Accuracy = 0.9995\n",
      "Epoch 67: Accuracy = 0.9995\n",
      "Epoch 68: Accuracy = 0.9995\n",
      "Epoch 69: Accuracy = 0.9995\n",
      "Epoch 70: Accuracy = 0.9995\n",
      "Epoch 71: Accuracy = 0.9997\n",
      "Epoch 72: Accuracy = 0.9997\n",
      "Epoch 73: Accuracy = 0.9995\n",
      "Epoch 74: Accuracy = 0.9995\n",
      "Epoch 75: Accuracy = 0.9997\n",
      "Epoch 76: Accuracy = 0.9997\n",
      "Epoch 77: Accuracy = 0.9997\n",
      "Epoch 78: Accuracy = 0.9995\n",
      "Epoch 79: Accuracy = 0.9995\n",
      "Epoch 80: Accuracy = 0.9997\n",
      "Epoch 81: Accuracy = 0.9995\n",
      "Epoch 82: Accuracy = 0.9997\n",
      "Epoch 83: Accuracy = 0.9995\n",
      "Epoch 84: Accuracy = 0.9995\n",
      "Epoch 85: Accuracy = 0.9995\n",
      "Epoch 86: Accuracy = 0.9995\n",
      "Epoch 87: Accuracy = 0.9995\n",
      "Epoch 88: Accuracy = 0.9995\n",
      "Epoch 89: Accuracy = 0.9997\n",
      "Epoch 90: Accuracy = 0.9997\n",
      "Epoch 91: Accuracy = 0.9979\n",
      "Epoch 92: Accuracy = 0.8765\n",
      "Epoch 93: Accuracy = 0.9454\n",
      "Epoch 94: Accuracy = 0.9826\n",
      "Epoch 95: Accuracy = 0.9907\n",
      "Epoch 96: Accuracy = 0.9959\n",
      "Epoch 97: Accuracy = 0.9917\n",
      "Epoch 98: Accuracy = 0.9933\n",
      "Epoch 99: Accuracy = 0.9935\n",
      "Epoch 100: Accuracy = 0.9959\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have the history object from model.fit()\n",
    "if 'history' in locals():\n",
    "    print(\"Epoch-wise Training Accuracy:\")\n",
    "    for epoch, acc in enumerate(history.history['accuracy'], 1):\n",
    "        print(f\"Epoch {epoch}: Accuracy = {acc:.4f}\")\n",
    "else:\n",
    "    print(\"The 'history' object from training is not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val_Accuracy after 100 epochs: 0.6977\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Val_Accuracy after {epochs} epochs: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
